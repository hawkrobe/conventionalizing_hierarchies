// run using, e.g.:
// WEBPPL_PARAM_PATH='./bdaOutput/'; echo $WEBPPL_PARAM_PATH; webppl BDA.wppl --param-store file --param-id game1 --require ./refModule/ -- --gameid game1

// Load in experimental data to condition on then reformat
var rawData = refModule.readCSV('../bdaInput/' + argv.gameid + '.csv');
var data = refModule.reformatData(rawData);
var numEpochs = 6;
var epochSize = data.length / numEpochs;
console.log("Loading expt data complete..." + data.length + " data points");

var globalConfig = {
  aggregate: false,
  outputFileName : argv.gameid + 'lexicalInference'
};

var utterances = map(function(i) {return 'word' + i;}, _.range(1, 17));
var states = ['blueSquare1', 'blueSquare2', 'redSquare1', 'redSquare2',
	      'spottedCircle1', 'spottedCircle2', 'stripedCircle1', 'stripedCircle2'];
var lexDims = [utterances.length,states.length];

var tensorSoftplus = function(x) {
  return T.log(T.add(T.exp(x), 1));
};

var lexiconGuide = function(paramName) {
  return function() {
    DiagCovGaussian({
      mu: param({name: paramName + 'mu', dims: lexDims}),
      sigma: tensorSoftplus(param({name: paramName + 'sigma', dims: lexDims}))
    });
  };
};

// Learn lexicon for each participant (aligned to their "final" roles at post-test)
var sampleHyperlexica = function(k) {
  var lexPrior = DiagCovGaussian({ mu: zeros(lexDims), sigma: T.mul(ones(lexDims), 5)});
  return {
    finalSpeaker:  sample(lexPrior, {guide: lexiconGuide('speakerHyp' + k)}),
    finalListener: sample(lexPrior, {guide: lexiconGuide('listenerHyp' + k)})
  };
};

var observeRound = function(params, datum) {
  // Align role swapping with final post-test measures
  var llex = datum.trialNum % 2 == 1 ? params.finalSpeaker : params.finalListener;
  var slex = datum.trialNum % 2 == 1 ? params.finalListener : params.finalSpeaker;

  // For speaker, we observe the word they chose given their intended target
  var speakerScore = refModule.getSpeakerScore(datum.wordID, datum.intendedName, {
    context: datum.context,
    lexicon: slex
  });
  factor(speakerScore);

  // For listener, we observe the object they clicked given the utterance they heard
  var listenerScore = refModule.getListenerScore(datum.clickedName, datum.wordID,{
    context: datum.context,
    lexicon: llex
  });
  factor(listenerScore);
};

var model = function() {
  // Sample a lexicon for each epoch
  var lexica = map(function(k) {return sampleHyperlexica(k);}, _.range(1,numEpochs + 1));

  // Observe all data on each gradient step (for gradient stability)
  mapData({data: data, batchSize: 96}, function(trialDatum) {
    var currQ = Math.floor((trialDatum.trialNum - 1) / epochSize);
    var lexiconParams = lexica[currQ];
    observeRound(lexiconParams, trialDatum);
  });
};

// This optimizes params in file store
Optimize({model: model, steps: 5000, verbose: true,
	  optMethod: {adam: {stepSize: 0.001}}});
